# Terminology and Metrics in Performance Analysis {#sec:secMetrics}

Like many engineering disciplines, performance analysis is quite heavy on using peculiar terms and metrics. For a beginner, it can be a very hard time looking into a profile generated by an analysis tool like Linux `perf` or Intel VTune Profiler. Those tools juggle many complex terms and metrics, however, these metrics are "must-knowns" if you're set to do any serious performance engineering work.

Since I have mentioned Linux `perf`, let me briefly introduce the tool as I have many examples of using it in this and later chapters. Linux `perf` is a performance profiler that you can use to find hotspots in a program, collect various low-level CPU performance events, analyze call stacks, and many other things. I will use Linux `perf` extensively throughout the book as it is one of the most popular performance analysis tools. Another reason why I prefer showcasing Linux `perf` is because it is open-source software, which enables enthusiastic readers to explore the mechanics of what's going on inside a modern profiling tool. This is especially useful for learning concepts presented in this book because GUI-based tools, like Intel® VTune™ Profiler, tend to hide all the complexity. We will have a more detailed overview of Linux `perf` in [@sec:secOverviewPerfTools].

This chapter is a gentle introduction to the basic terminology and metrics used in performance analysis. We will first define the basic things like retired/executed instructions, IPC/CPI, $\mu$ops, core/reference clocks, cache misses, and branch mispredictions. Then we will see how to measure the memory latency and bandwidth of a system and introduce some more advanced metrics. In the end, we will benchmark four industry workloads and look at the collected metrics.
